#!/usr/bin/env python3
"""
NaverBlogAutoPilot - ë©”ì¸ CLI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸

ì‚¬ìš©ë²•:
    python main.py init-db                    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    python main.py crawl [--limit N]          # silmu.kr í¬ë¡¤ë§
    python main.py research                   # í‚¤ì›Œë“œ ë¶„ì„
    python main.py generate [--count N]       # í¬ìŠ¤íŠ¸ ìƒì„±
    python main.py publish                    # ë¸”ë¡œê·¸ ë°œí–‰
    python main.py monitor                    # ìˆœìœ„ ì¶”ì 
    python main.py report --type weekly       # ë¦¬í¬íŠ¸ ìƒì„±
    python main.py schedule                   # ìë™ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
    python main.py status                     # í˜„ì¬ ìƒíƒœ í™•ì¸
"""

import asyncio
import sys
import argparse
import time
from datetime import datetime

try:
    import schedule
except ImportError:
    schedule = None

from config.settings import settings
from utils.database import Database
from utils.logger import setup_logger, get_logger


def get_db() -> Database:
    """ë°ì´í„°ë² ì´ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return Database(settings.DB_PATH)


# ============================================================
# CLI ëª…ë ¹ì–´ í•¸ë“¤ëŸ¬
# ============================================================

def cmd_init_db(args):
    """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    logger = get_logger()
    db = get_db()
    db.init_db()
    logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ!")
    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ!")


def cmd_crawl(args):
    """Phase 1: silmu.kr í¬ë¡¤ë§"""
    from modules.collector import SilmuCrawler

    logger = get_logger()
    limit = args.limit if hasattr(args, "limit") else None

    logger.info(f"í¬ë¡¤ë§ ì‹œì‘ (limit={limit})")
    print(f"ğŸ•·ï¸  silmu.kr í¬ë¡¤ë§ ì‹œì‘... (limit={limit or 'ì „ì²´'})")

    db = get_db()
    crawler = SilmuCrawler(db=db)
    count = asyncio.run(crawler.crawl(limit=limit))

    logger.info(f"í¬ë¡¤ë§ ì™„ë£Œ: {count}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘")
    print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! {count}ê°œ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")


def cmd_research(args):
    """Phase 2: í‚¤ì›Œë“œ ë¶„ì„"""
    import json
    from modules.researcher import KeywordAnalyzer, TrendTracker, CompetitorScanner

    logger = get_logger()
    logger.info("í‚¤ì›Œë“œ ë¶„ì„ ì‹œì‘")
    print("ğŸ” í‚¤ì›Œë“œ ë¶„ì„ ì‹œì‘...")

    # í‚¤ì›Œë“œ í´ëŸ¬ìŠ¤í„° ë¡œë“œ
    clusters_path = settings.BASE_DIR / "config" / "keyword_clusters.json"
    with open(clusters_path, "r", encoding="utf-8") as f:
        clusters_data = json.load(f)

    db = get_db()

    # ëª¨ë“  ì‹œë“œ í‚¤ì›Œë“œ ìˆ˜ì§‘
    all_keywords = []
    for cluster_name, cluster_info in clusters_data["clusters"].items():
        all_keywords.extend(cluster_info["seed_keywords"])

    async def run_research():
        # 1. í‚¤ì›Œë“œ í™•ì¥ (ìë™ì™„ì„±, ì—°ê´€ê²€ìƒ‰ì–´)
        tracker = TrendTracker(db)
        expanded = await tracker.expand_keywords(all_keywords[:10])
        print(f"  ğŸ“Š í‚¤ì›Œë“œ í™•ì¥ ì™„ë£Œ: {sum(len(v) for v in expanded.values())}ê°œ ì¶”ê°€ í‚¤ì›Œë“œ")

        # 2. ê²€ìƒ‰ëŸ‰ ë¶„ì„
        analyzer = KeywordAnalyzer(db)
        results = await analyzer.analyze_keywords(all_keywords)
        print(f"  ğŸ“ˆ ê²€ìƒ‰ëŸ‰ ë¶„ì„ ì™„ë£Œ: {len(results)}ê°œ í‚¤ì›Œë“œ")

        # 3. ê²½ìŸ ë¶„ì„ (ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë§Œ)
        scanner = CompetitorScanner(db)
        top_keywords = sorted(results, key=lambda x: x.get("total_score", 0), reverse=True)[:5]
        for kw_data in top_keywords:
            keyword = kw_data.get("keyword", "")
            if keyword:
                comp = await scanner.analyze_competitors(keyword)
                print(f"  ğŸ† ê²½ìŸ ë¶„ì„: '{keyword}' - ê²½ìŸë„ {comp.get('competition_score', 0):.1f}")

    asyncio.run(run_research())

    logger.info("í‚¤ì›Œë“œ ë¶„ì„ ì™„ë£Œ")
    print("âœ… í‚¤ì›Œë“œ ë¶„ì„ ì™„ë£Œ!")


def _get_current_publish_category(db) -> str:
    """í˜„ì¬ ë°œí–‰í•´ì•¼ í•  ì¹´í…Œê³ ë¦¬ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.

    ë¡œì§:
    1. ë°œí–‰ ìˆœì„œ(PUBLISH_CATEGORY_ORDER)ë¥¼ ë”°ë¦„
    2. ê° ì¹´í…Œê³ ë¦¬ì— POSTS_PER_CATEGORY_ROTATEê°œë¥¼ ë°œí–‰í•œ í›„ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ
    3. ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¥¼ í•œ ë°”í€´ ëŒë©´ ë‹¤ì‹œ ì²˜ìŒë¶€í„°
    """
    order = settings.PUBLISH_CATEGORY_ORDER
    rotate_count = settings.POSTS_PER_CATEGORY_ROTATE

    # ê° ì¹´í…Œê³ ë¦¬ë³„ ë°œí–‰(published) + ìŠ¹ì¸(approved) í¬ìŠ¤íŠ¸ ìˆ˜ í™•ì¸
    for publish_cat in order:
        # ì´ ì¹´í…Œê³ ë¦¬ì—ì„œ ë°œí–‰/ìŠ¹ì¸ëœ í¬ìŠ¤íŠ¸ ìˆ˜
        count = db.count("posts", "publish_category = ? AND status IN ('published', 'approved')", (publish_cat,))
        if count < rotate_count:
            return publish_cat

    # ëª¨ë“  ì¹´í…Œê³ ë¦¬ê°€ rotate_countë¥¼ ì±„ìš´ ê²½ìš° â†’ 2ë¼ìš´ë“œ ì²´í¬
    # ì „ì²´ ë°œí–‰ ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í˜„ì¬ ë¼ìš´ë“œì™€ ì¹´í…Œê³ ë¦¬ ê²°ì •
    total_published = db.count("posts", "status IN ('published', 'approved')")
    total_per_round = rotate_count * len(order)

    if total_per_round == 0:
        return order[0]

    position_in_round = total_published % total_per_round
    category_index = position_in_round // rotate_count
    return order[min(category_index, len(order) - 1)]


def cmd_generate(args):
    """Phase 3: í¬ìŠ¤íŠ¸ ìƒì„± (ì¹´í…Œê³ ë¦¬ ìˆœì„œ ê¸°ë°˜)"""
    from modules.generator import ContentEngine, SEOOptimizer, QualityChecker

    logger = get_logger()
    count = args.count if hasattr(args, "count") else 1
    category = args.category if hasattr(args, "category") and args.category else None

    db = get_db()

    # ì¹´í…Œê³ ë¦¬ ê²°ì •
    if not category:
        category = _get_current_publish_category(db)

    logger.info(f"í¬ìŠ¤íŠ¸ ìƒì„± ì‹œì‘ (count={count}, category={category})")
    print(f"âœï¸  í¬ìŠ¤íŠ¸ ìƒì„± ì‹œì‘... ({count}ê°œ, ì¹´í…Œê³ ë¦¬: {category})")

    # í¬ë¡¤ë§ ì¹´í…Œê³ ë¦¬ â†’ ë°œí–‰ ì¹´í…Œê³ ë¦¬ ì—­ë§¤í•‘ (ì–´ë–¤ í¬ë¡¤ë§ ì¹´í…Œê³ ë¦¬ê°€ ì´ ë°œí–‰ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ”ì§€)
    source_categories = [
        crawl_cat for crawl_cat, pub_cat in settings.CATEGORY_MAP.items()
        if pub_cat == category
    ]
    if not source_categories:
        # ë§¤í•‘ì´ ì—†ìœ¼ë©´ ë™ì¼ ì´ë¦„ìœ¼ë¡œ ì‹œë„
        source_categories = [category]

    source_placeholders = ",".join(["?"] * len(source_categories))

    async def run_generate():
        engine = ContentEngine(db)
        seo = SEOOptimizer()
        quality = QualityChecker()

        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ë¯¸ì‚¬ìš© ê¸°ì‚¬ ì„ íƒ
        articles = db.execute(
            f"""SELECT a.id, a.title, pa.clean_text, a.category, a.url
               FROM articles a
               JOIN processed_articles pa ON pa.article_id = a.id
               WHERE a.id NOT IN (SELECT COALESCE(article_id, 0) FROM posts)
               AND a.category IN ({source_placeholders})
               ORDER BY a.crawled_at DESC
               LIMIT ?""",
            (*source_categories, count),
        )

        if not articles:
            # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì— ê¸°ì‚¬ê°€ ì—†ìœ¼ë©´ ì „ì²´ì—ì„œ ì„ íƒ
            logger.warning(f"'{category}' ì¹´í…Œê³ ë¦¬ì— ë¯¸ì‚¬ìš© ê¸°ì‚¬ê°€ ì—†ì–´ ì „ì²´ì—ì„œ ì„ íƒí•©ë‹ˆë‹¤")
            print(f"  âš ï¸  '{category}' ì¹´í…Œê³ ë¦¬ ê¸°ì‚¬ ë¶€ì¡± â†’ ì „ì²´ì—ì„œ ì„ íƒ")
            articles = db.execute(
                """SELECT a.id, a.title, pa.clean_text, a.category
                   FROM articles a
                   JOIN processed_articles pa ON pa.article_id = a.id
                   WHERE a.id NOT IN (SELECT COALESCE(article_id, 0) FROM posts)
                   ORDER BY a.crawled_at DESC
                   LIMIT ?""",
                (count,),
            )

        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ìš°ì„  ì„ íƒ
        keywords = db.execute(
            f"""SELECT id, keyword, cluster, total_score
               FROM keywords
               WHERE id NOT IN (SELECT COALESCE(keyword_id, 0) FROM posts)
               AND cluster IN ({source_placeholders})
               ORDER BY total_score DESC
               LIMIT ?""",
            (*source_categories, count),
        )

        if not keywords:
            # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì „ì²´ì—ì„œ ì„ íƒ
            keywords = db.execute(
                """SELECT id, keyword, cluster, total_score
                   FROM keywords
                   WHERE id NOT IN (SELECT COALESCE(keyword_id, 0) FROM posts)
                   ORDER BY total_score DESC
                   LIMIT ?""",
                (count,),
            )

        generated = 0
        for i in range(min(count, len(articles), max(len(keywords), 1))):
            article = dict(articles[i]) if i < len(articles) else None
            keyword = dict(keywords[i]) if i < len(keywords) else None

            if not article:
                logger.warning("ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤")
                break

            try:
                post = await engine.generate_post(article, keyword or {})

                # ë°œí–‰ ì¹´í…Œê³ ë¦¬ íƒœê¹… (DBì—ë„ ë°˜ì˜)
                post["publish_category"] = category
                if post.get("id"):
                    db.execute(
                        "UPDATE posts SET publish_category = ? WHERE id = ?",
                        (category, post["id"]),
                    )

                # SEO ì ìˆ˜ ê³„ì‚°
                seo_result = seo.calculate_score(
                    post["title"], post["body"], keyword.get("keyword", "") if keyword else ""
                )
                post["seo_score"] = seo_result["total_score"]

                # í’ˆì§ˆ ê²€ì‚¬ (ì›ë³¸ í‘œì ˆ)
                quality_result = quality.check_plagiarism(
                    post["body"], article.get("clean_text", "")
                )

                # ê¸°ì¡´ ë°œí–‰ ê¸€ ì¤‘ë³µ ê²€ì‚¬
                dup_result = quality.check_duplicate(post["title"], post["body"], db, exclude_post_id=post.get("id"))

                if dup_result["is_duplicate"]:
                    post["status"] = "draft"
                    print(f"  ğŸ”„ [{i+1}/{count}] [{category}] '{post['title']}' - ì¤‘ë³µ ê°ì§€: {dup_result['reason']}")
                    print(f"     ìœ ì‚¬ ê¸€: '{dup_result['most_similar_title'][:40]}...'")
                elif seo_result["total_score"] >= settings.MIN_SEO_SCORE and quality_result <= settings.PLAGIARISM_THRESHOLD:
                    post["status"] = "approved"
                    print(f"  âœ… [{i+1}/{count}] [{category}] '{post['title']}' - SEO: {seo_result['total_score']:.0f}ì ")
                else:
                    post["status"] = "draft"
                    print(f"  âš ï¸  [{i+1}/{count}] [{category}] '{post['title']}' - SEO: {seo_result['total_score']:.0f}ì  (ì¬ê²€í†  í•„ìš”)")

                # DBì— statusì™€ seo_score ë°˜ì˜
                if post.get("id"):
                    db.execute(
                        "UPDATE posts SET status = ?, seo_score = ? WHERE id = ?",
                        (post["status"], seo_result["total_score"], post["id"]),
                    )

                generated += 1

            except Exception as e:
                logger.error(f"í¬ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
                print(f"  âŒ [{i+1}/{count}] ìƒì„± ì‹¤íŒ¨: {e}")

        return generated

    generated = asyncio.run(run_generate())

    logger.info(f"í¬ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ: {generated}ê°œ (ì¹´í…Œê³ ë¦¬: {category})")
    print(f"âœ… í¬ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ! {generated}ê°œ ìƒì„±ë¨ (ì¹´í…Œê³ ë¦¬: {category})")


def cmd_publish(args):
    """Phase 4: ë¸”ë¡œê·¸ ë°œí–‰ (ì¹´í…Œê³ ë¦¬ ìˆœì„œ ê¸°ë°˜)"""
    from modules.publisher import AntiDetection, NaverBlogPoster

    logger = get_logger()
    logger.info("ë°œí–‰ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
    print("ğŸ“¤ ë°œí–‰ í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")

    db = get_db()
    anti = AntiDetection(db)

    # ì–´ë·°ì§• ë°©ì§€ ì²´í¬ (--force ì˜µì…˜ìœ¼ë¡œ ë¬´ì‹œ ê°€ëŠ¥)
    force = getattr(args, "force", False)
    if force:
        print("âš ï¸  --force ëª¨ë“œ: ì•ˆí‹°ë””í…ì…˜ ê°„ê²© ì²´í¬ ë¬´ì‹œ")
        logger.warning("--force ëª¨ë“œ: ì•ˆí‹°ë””í…ì…˜ ê°„ê²© ì²´í¬ ë¬´ì‹œ")
    else:
        can_publish, reason = anti.can_publish()
        if not can_publish:
            next_time = anti.get_next_publish_time()
            print(f"â³ ë°œí–‰ ë¶ˆê°€: {reason}")
            print(f"   ë‹¤ìŒ ë°œí–‰ ê°€ëŠ¥ ì‹œê°„: {next_time.strftime('%Y-%m-%d %H:%M')}")
            return

    # í˜„ì¬ ë°œí–‰í•  ì¹´í…Œê³ ë¦¬ í™•ì¸
    current_category = _get_current_publish_category(db)
    print(f"  ğŸ“‚ í˜„ì¬ ë°œí–‰ ì¹´í…Œê³ ë¦¬: {current_category}")

    # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ìŠ¹ì¸ëœ í¬ìŠ¤íŠ¸ ìš°ì„  ì„ íƒ
    posts = db.execute(
        """SELECT id, title, body, html_body, publish_category
           FROM posts
           WHERE status = 'approved' AND publish_category = ?
           ORDER BY seo_score DESC
           LIMIT 1""",
        (current_category,),
    )

    if not posts:
        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì— ì—†ìœ¼ë©´ ì „ì²´ì—ì„œ ì„ íƒ
        posts = db.execute(
            """SELECT id, title, body, html_body, publish_category
               FROM posts
               WHERE status = 'approved'
               ORDER BY seo_score DESC
               LIMIT 1"""
        )

    if not posts:
        print("ğŸ“­ ë°œí–‰í•  í¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € generateë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    post = dict(posts[0])
    pub_cat = post.get("publish_category", "ë¯¸ë¶„ë¥˜")
    print(f"  ğŸ“ ë°œí–‰ ëŒ€ìƒ: [{pub_cat}] {post['title']}")

    # â”€â”€ ë°œí–‰ ì „ íœ´ë¨¼ ë¦¬ë·° (--skip-reviewë¡œ ê±´ë„ˆë›¸ ìˆ˜ ìˆìŒ) â”€â”€
    skip_review = getattr(args, "skip_review", False)
    if not skip_review and post.get("body"):
        try:
            from modules.generator.humanizer import detect_ai_patterns
            print(f"\n  ğŸ” ë°œí–‰ ì „ íœ´ë¨¼ ë¦¬ë·° ì‹¤í–‰ ì¤‘...")
            review = detect_ai_patterns(post["body"])

            score = review.score
            if score >= 80:
                indicator = "ğŸŸ¢"
            elif score >= 60:
                indicator = "ğŸŸ¡"
            else:
                indicator = "ğŸ”´"
            print(f"  {indicator} íœ´ë¨¼ ë¦¬ë·° ì ìˆ˜: {score}/100")

            if review.issues:
                for iss in review.issues[:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                    print(f"     âš ï¸  [{iss['category']}] {iss['detail']}")
                if len(review.issues) > 3:
                    print(f"     ... ì™¸ {len(review.issues) - 3}ê°œ ì´ìŠˆ")

            if score < 50:
                print(f"\n  ğŸš« íœ´ë¨¼ ë¦¬ë·° ì ìˆ˜ê°€ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤ ({score}/100).")
                print(f"     ë¨¼ì € 'python main.py review --fix --id {post['id']}' ë¡œ ìˆ˜ì •í•˜ì„¸ìš”.")
                print(f"     ê°•í–‰í•˜ë ¤ë©´: python main.py publish --skip-review")
                return
            elif score < 70:
                print(f"\n  âš ï¸  AI ê°ì§€ ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤. ìˆ˜ì •ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
                print(f"     ìˆ˜ì •: python main.py review --fix --id {post['id']}")
                print(f"     (3ì´ˆ í›„ ë°œí–‰ì„ ê³„ì†í•©ë‹ˆë‹¤...)")
                import time as time_module
                time_module.sleep(3)

            print()
        except Exception as e:
            logger.warning(f"íœ´ë¨¼ ë¦¬ë·° ìŠ¤í‚µ: {e}")

    async def run_publish():
        poster = NaverBlogPoster(db)
        result = await poster.publish(post)  # publish ë‚´ë¶€ì—ì„œ _close() ì²˜ë¦¬
        if result.get("success"):
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            db.execute(
                "UPDATE posts SET status = 'published' WHERE id = ?",
                (post["id"],),
            )
            print(f"âœ… ë°œí–‰ ì„±ê³µ!")
            print(f"   ì¹´í…Œê³ ë¦¬: {pub_cat}")
            print(f"   ì œëª©: {post['title']}")
            print(f"   URL: {result.get('blog_url', 'N/A')}")
        else:
            print(f"âŒ ë°œí–‰ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
            # ë””ë²„ê¹… ìŠ¤í¬ë¦°ìƒ· í™•ì¸ ì•ˆë‚´
            print(f"   ğŸ’¡ ë””ë²„ê¹… ìŠ¤í¬ë¦°ìƒ·: data/debug_screenshots/ í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”")

    asyncio.run(run_publish())


def cmd_monitor(args):
    """Phase 5: ìˆœìœ„ ì¶”ì """
    from modules.monitor import RankingTracker

    logger = get_logger()
    logger.info("ìˆœìœ„ ì¶”ì  ì‹œì‘")
    print("ğŸ“Š ìˆœìœ„ ì¶”ì  ì‹œì‘...")

    db = get_db()

    async def run_monitor():
        tracker = RankingTracker(db)
        rankings = await tracker.check_rankings()
        return rankings

    rankings = asyncio.run(run_monitor())

    if rankings:
        print(f"\nğŸ“ˆ ìˆœìœ„ ê²°ê³¼ ({len(rankings)}ê°œ í‚¤ì›Œë“œ):")
        for r in rankings:
            rank = r.get("rank", "ìˆœìœ„ ì™¸")
            print(f"  â€¢ '{r.get('keyword', '')}' â†’ {rank}ìœ„")
    else:
        print("ğŸ“­ ì¶”ì í•  ë°œí–‰ í¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    print("âœ… ìˆœìœ„ ì¶”ì  ì™„ë£Œ!")


def cmd_report(args):
    """Phase 5: ë¦¬í¬íŠ¸ ìƒì„±"""
    from modules.monitor import ReportGenerator

    logger = get_logger()
    report_type = args.type if hasattr(args, "type") else "weekly"

    logger.info(f"ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘ ({report_type})")
    print(f"ğŸ“‹ {report_type} ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")

    db = get_db()
    generator = ReportGenerator(db)

    if report_type == "weekly":
        report_path = generator.generate_weekly_report()
    elif report_type == "monthly":
        report_path = generator.generate_monthly_report()
    else:
        print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¦¬í¬íŠ¸ íƒ€ì…: {report_type}")
        return

    print(f"âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
    print(f"   íŒŒì¼: {report_path}")


def cmd_schedule(args):
    """ìë™ ìŠ¤ì¼€ì¤„ëŸ¬"""
    logger = get_logger()
    logger.info("ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")
    print("â° ìë™ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘!")
    print(f"   í¬ë¡¤ë§: ë§¤ì¼ {settings.SCHEDULE_CRAWL_HOUR}")
    print(f"   ë°œí–‰: ë§¤ì¼ {', '.join(settings.SCHEDULE_PUBLISH_HOURS)}")
    print(f"   ëª¨ë‹ˆí„°ë§: ë§¤ì¼ {settings.SCHEDULE_MONITOR_HOUR}")
    print("   ì¢…ë£Œ: Ctrl+C\n")

    # í¬ë¡¤ë§ ìŠ¤ì¼€ì¤„
    schedule.every().day.at(settings.SCHEDULE_CRAWL_HOUR).do(
        lambda: cmd_crawl(argparse.Namespace(limit=20))
    )

    # ë°œí–‰ ìŠ¤ì¼€ì¤„
    for pub_hour in settings.SCHEDULE_PUBLISH_HOURS:
        schedule.every().day.at(pub_hour).do(
            lambda: (
                cmd_generate(argparse.Namespace(count=1)),
                cmd_publish(argparse.Namespace()),
            )
        )

    # ëª¨ë‹ˆí„°ë§ ìŠ¤ì¼€ì¤„
    schedule.every().day.at(settings.SCHEDULE_MONITOR_HOUR).do(
        lambda: cmd_monitor(argparse.Namespace())
    )

    # ì£¼ê°„ ë¦¬í¬íŠ¸ (ì›”ìš”ì¼)
    schedule.every().monday.at("09:00").do(
        lambda: cmd_report(argparse.Namespace(type="weekly"))
    )

    try:
        while True:
            schedule.run_pending()
            time.sleep(60)
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ")


def cmd_status(args):
    """í˜„ì¬ ìƒíƒœ í™•ì¸"""
    db = get_db()
    print("\nğŸ“Š NaverBlogAutoPilot ìƒíƒœ")
    print("=" * 50)

    try:
        articles = db.count("articles")
        keywords = db.count("keywords")
        posts_draft = db.count("posts", "status='draft'")
        posts_approved = db.count("posts", "status='approved'")
        posts_published = db.count("posts", "status='published'")
        published_today = db.count(
            "posting_history",
            "publish_status='success' AND date(published_at)=date('now')",
        )
        published_week = db.count(
            "posting_history",
            "publish_status='success' AND published_at >= datetime('now', '-7 days')",
        )

        print(f"  ğŸ“° ìˆ˜ì§‘ëœ ê¸°ì‚¬:     {articles}ê°œ")
        print(f"  ğŸ”‘ ë¶„ì„ëœ í‚¤ì›Œë“œ:   {keywords}ê°œ")
        print(f"  âœï¸  ì´ˆì•ˆ í¬ìŠ¤íŠ¸:     {posts_draft}ê°œ")
        print(f"  âœ… ìŠ¹ì¸ëœ í¬ìŠ¤íŠ¸:   {posts_approved}ê°œ")
        print(f"  ğŸ“¤ ë°œí–‰ëœ í¬ìŠ¤íŠ¸:   {posts_published}ê°œ")
        print(f"  ğŸ“… ì˜¤ëŠ˜ ë°œí–‰:       {published_today}ê°œ / {settings.MAX_POSTS_PER_DAY}ê°œ")
        print(f"  ğŸ“… ì´ë²ˆ ì£¼ ë°œí–‰:    {published_week}ê°œ / {settings.MAX_POSTS_PER_WEEK}ê°œ")

        # ì¹´í…Œê³ ë¦¬ë³„ í˜„í™©
        current_cat = _get_current_publish_category(db)
        print(f"\n  ğŸ“‚ ì¹´í…Œê³ ë¦¬ë³„ í˜„í™© (ë°œí–‰ ìˆœì„œ):")
        for cat in settings.PUBLISH_CATEGORY_ORDER:
            cat_count = db.count("posts", "publish_category = ? AND status IN ('published', 'approved')", (cat,))
            marker = " â—€ í˜„ì¬" if cat == current_cat else ""
            bar = "â–ˆ" * cat_count + "â–‘" * (settings.POSTS_PER_CATEGORY_ROTATE - cat_count)
            print(f"     {cat}: [{bar}] {cat_count}/{settings.POSTS_PER_CATEGORY_ROTATE}{marker}")

        # ìµœê·¼ ë°œí–‰
        recent = db.execute(
            """SELECT p.title, ph.blog_url, ph.published_at
               FROM posting_history ph
               JOIN posts p ON p.id = ph.post_id
               WHERE ph.publish_status = 'success'
               ORDER BY ph.published_at DESC
               LIMIT 3"""
        )
        if recent:
            print(f"\n  ğŸ“Œ ìµœê·¼ ë°œí–‰:")
            for r in recent:
                print(f"     â€¢ {r['title'][:40]}... ({r['published_at'][:10]})")

    except Exception as e:
        print(f"  âš ï¸  ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨ (DB ì´ˆê¸°í™” í•„ìš”?): {e}")
        print(f"     python main.py init-db ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")

    print()


def cmd_review(args):
    """Phase 3.5: í¬ìŠ¤íŠ¸ íœ´ë¨¼ ë¦¬ë·° (AI ê°ì§€ íšŒí”¼ ê²€í† )"""
    from modules.generator.humanizer import Humanizer, detect_ai_patterns

    logger = get_logger()
    db = get_db()

    post_id = getattr(args, "id", None)
    fix = getattr(args, "fix", False)
    all_posts = getattr(args, "all", False)

    # ëŒ€ìƒ í¬ìŠ¤íŠ¸ ì„ íƒ
    if post_id:
        posts = db.execute(
            "SELECT id, title, body, html_body, status, publish_category FROM posts WHERE id = ?",
            (post_id,),
        )
    elif all_posts:
        posts = db.execute(
            "SELECT id, title, body, html_body, status, publish_category FROM posts WHERE status IN ('approved', 'draft') ORDER BY id"
        )
    else:
        # approvedë§Œ ê¸°ë³¸ ëŒ€ìƒ
        posts = db.execute(
            "SELECT id, title, body, html_body, status, publish_category FROM posts WHERE status = 'approved' ORDER BY id"
        )

    if not posts:
        print("ğŸ“­ ë¦¬ë·°í•  í¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ” íœ´ë¨¼ ë¦¬ë·° ì‹œì‘ ({len(posts)}ê°œ í¬ìŠ¤íŠ¸)")
    print("=" * 60)

    humanizer = Humanizer(db) if fix else None
    total_issues = 0

    for p in posts:
        p = dict(p)
        body = p.get("body", "")
        if not body:
            continue

        print(f"\nğŸ“ #{p['id']} [{p['status']}] {p['title'][:45]}...")

        # íŒ¨í„´ ê°ì§€
        review = detect_ai_patterns(body)
        total_issues += len(review.issues)

        # ì ìˆ˜ í‘œì‹œ (ìƒ‰ìƒ ë°”)
        score = review.score
        if score >= 80:
            bar_color = "ğŸŸ¢"
        elif score >= 60:
            bar_color = "ğŸŸ¡"
        else:
            bar_color = "ğŸ”´"
        filled = score // 5
        empty = 20 - filled
        bar = "â–ˆ" * filled + "â–‘" * empty
        print(f"   {bar_color} ì ìˆ˜: [{bar}] {score}/100")

        if review.issues:
            for iss in review.issues:
                sev_bar = "â—" * min(iss["severity"], 10)
                print(f"   âš ï¸  [{iss['category']}] {iss['detail']}")
                print(f"      ì‹¬ê°ë„: {sev_bar} ({iss['severity']}/10)")

        # --fix ì˜µì…˜: ì‹¤ì œ ìˆ˜ì • ì ìš©
        if fix and humanizer and review.needs_rewrite:
            print(f"   ğŸ”„ ë¦¬ë¼ì´íŒ… ì‹¤í–‰ ì¤‘...")
            # DBì—ì„œ ì‹¤ì œ í‚¤ì›Œë“œ ì¡°íšŒ (keyword_id â†’ keywords í…Œì´ë¸”)
            keyword = ""
            kw_row = db.execute(
                "SELECT k.keyword FROM keywords k JOIN posts p ON p.keyword_id = k.id WHERE p.id = ?",
                (p["id"],),
            )
            if kw_row:
                keyword = kw_row[0]["keyword"] if isinstance(kw_row[0], dict) else kw_row[0][0]
            else:
                # fallback: ì œëª©ì—ì„œ ì¶”ì¶œ
                kw_parts = p["title"].split()
                keyword = kw_parts[0] if kw_parts else ""
            print(f"   ğŸ“Œ íƒ€ê²Ÿ í‚¤ì›Œë“œ: \"{keyword}\"")

            fixed_body, post_review = humanizer.review_and_fix(
                body, p["title"], keyword, force_rewrite=True
            )

            if fixed_body != body:
                # HTML ì¬ë³€í™˜
                from modules.generator.content_engine import ContentEngine
                # ContentEngineì€ anthropic í•„ìš” â€” HTML ë³€í™˜ë§Œ ì‚¬ìš©
                import types
                from modules.generator import content_engine as ce_mod
                import re as re_module

                class DummyEngine:
                    pass

                engine = DummyEngine()
                for method_name in ['_convert_to_html', '_convert_tables_to_html', '_build_html_table',
                                    '_insert_info_cards', '_create_summary_card', '_create_highlight_box',
                                    '_create_checklist_card', '_create_cta_card']:
                    method = getattr(ce_mod.ContentEngine, method_name)
                    setattr(engine, method_name, types.MethodType(method, engine))

                html_body = engine._convert_to_html(fixed_body)
                html_body = engine._insert_info_cards(html_body, p["title"], keyword)

                # ì œëª© ì¤‘ë³µ ì œê±°
                html_body = re_module.sub(
                    r'<p style="font-size: 16px;[^"]*">\s*#\s+[^<]+</p>\s*',
                    '', html_body, count=1
                )

                # DB ì—…ë°ì´íŠ¸
                db.execute(
                    "UPDATE posts SET body = ?, html_body = ? WHERE id = ?",
                    (fixed_body, html_body, p["id"]),
                )
                print(f"   âœ… ìˆ˜ì • ì™„ë£Œ! (ì ìˆ˜: {review.score} â†’ {post_review.score})")
            else:
                print(f"   â„¹ï¸  ë¦¬ë¼ì´íŒ… ê²°ê³¼ê°€ ì›ë³¸ê³¼ ë™ì¼ (ë³€ê²½ ì—†ìŒ)")
        elif fix and review.needs_rewrite is False:
            print(f"   âœ… ì ìˆ˜ ì–‘í˜¸ â€” ìˆ˜ì • ë¶ˆí•„ìš”")

    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š ì „ì²´ ê²°ê³¼: {len(posts)}ê°œ í¬ìŠ¤íŠ¸, {total_issues}ê°œ ì´ìŠˆ ê°ì§€")
    if not fix and total_issues > 0:
        print(f"   ğŸ’¡ ìˆ˜ì •í•˜ë ¤ë©´: python main.py review --fix")


# ============================================================
# ë©”ì¸
# ============================================================

def main():
    """CLI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    # í™˜ê²½ ì„¤ì •
    settings.ensure_dirs()
    setup_logger(settings.LOG_LEVEL, settings.LOG_DIR)

    parser = argparse.ArgumentParser(
        description="NaverBlogAutoPilot - ë„¤ì´ë²„ ë¸”ë¡œê·¸ ìë™ ë°œí–‰ ì‹œìŠ¤í…œ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python main.py init-db                  # DB ì´ˆê¸°í™”
  python main.py crawl --limit 5          # ê¸°ì‚¬ 5ê°œ í¬ë¡¤ë§
  python main.py research                 # í‚¤ì›Œë“œ ë¶„ì„
  python main.py generate --count 1       # í¬ìŠ¤íŠ¸ 1ê°œ ìƒì„±
  python main.py review                   # AI ê°ì§€ íšŒí”¼ ê²€í† 
  python main.py review --fix             # ê²€í†  + ìë™ ìˆ˜ì •
  python main.py publish                  # ë°œí–‰
  python main.py monitor                  # ìˆœìœ„ ì¶”ì 
  python main.py report --type weekly     # ì£¼ê°„ ë¦¬í¬íŠ¸
  python main.py schedule                 # ìë™ ìŠ¤ì¼€ì¤„ëŸ¬
  python main.py status                   # ìƒíƒœ í™•ì¸
        """,
    )

    subparsers = parser.add_subparsers(dest="command", help="ì‹¤í–‰í•  ëª…ë ¹")

    # init-db
    subparsers.add_parser("init-db", help="ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”")

    # crawl
    crawl_parser = subparsers.add_parser("crawl", help="silmu.kr í¬ë¡¤ë§")
    crawl_parser.add_argument("--limit", type=int, default=None, help="í¬ë¡¤ë§í•  ê¸°ì‚¬ ìˆ˜ ì œí•œ")

    # research
    subparsers.add_parser("research", help="í‚¤ì›Œë“œ ë¶„ì„")

    # generate
    gen_parser = subparsers.add_parser("generate", help="í¬ìŠ¤íŠ¸ ìƒì„±")
    gen_parser.add_argument("--count", type=int, default=1, help="ìƒì„±í•  í¬ìŠ¤íŠ¸ ìˆ˜")
    gen_parser.add_argument("--category", type=str, default=None, help="ì¹´í…Œê³ ë¦¬ ì§€ì • (ì˜ˆ: ê³„ì•½/ì¡°ë‹¬)")

    # review (NEW: íœ´ë¨¼ ë¦¬ë·°)
    review_parser = subparsers.add_parser("review", help="AI ê°ì§€ íšŒí”¼ ê²€í†  (íœ´ë¨¼ ë¦¬ë·°)")
    review_parser.add_argument("--id", type=int, default=None, help="íŠ¹ì • í¬ìŠ¤íŠ¸ IDë§Œ ê²€í† ")
    review_parser.add_argument("--fix", action="store_true", help="ê°ì§€ëœ ë¬¸ì œë¥¼ ìë™ ìˆ˜ì • (Claude API ì‚¬ìš©)")
    review_parser.add_argument("--all", action="store_true", help="draft í¬í•¨ ì „ì²´ ê²€í† ")

    # publish
    publish_parser = subparsers.add_parser("publish", help="ë¸”ë¡œê·¸ ë°œí–‰")
    publish_parser.add_argument("--force", action="store_true", help="ì•ˆí‹°ë””í…ì…˜ ê°„ê²© ì²´í¬ ë¬´ì‹œ (í…ŒìŠ¤íŠ¸ìš©)")
    publish_parser.add_argument("--skip-review", action="store_true", help="ë°œí–‰ ì „ íœ´ë¨¼ ë¦¬ë·° ìŠ¤í‚µ")

    # monitor
    subparsers.add_parser("monitor", help="ìˆœìœ„ ì¶”ì ")

    # report
    report_parser = subparsers.add_parser("report", help="ë¦¬í¬íŠ¸ ìƒì„±")
    report_parser.add_argument("--type", choices=["weekly", "monthly"], default="weekly", help="ë¦¬í¬íŠ¸ íƒ€ì…")

    # schedule
    subparsers.add_parser("schedule", help="ìë™ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")

    # status
    subparsers.add_parser("status", help="í˜„ì¬ ìƒíƒœ í™•ì¸")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        sys.exit(0)

    # í™˜ê²½ë³€ìˆ˜ ê²€ì¦ (init-db, status ì œì™¸)
    if args.command not in ("init-db", "status"):
        missing = settings.validate()
        if missing and args.command not in ("crawl",):
            print(f"âš ï¸  í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ëˆ„ë½: {', '.join(missing)}")
            print(f"   .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            if args.command in ("publish", "generate"):
                sys.exit(1)

    # ëª…ë ¹ ì‹¤í–‰
    commands = {
        "init-db": cmd_init_db,
        "crawl": cmd_crawl,
        "research": cmd_research,
        "generate": cmd_generate,
        "review": cmd_review,
        "publish": cmd_publish,
        "monitor": cmd_monitor,
        "report": cmd_report,
        "schedule": cmd_schedule,
        "status": cmd_status,
    }

    cmd_func = commands.get(args.command)
    if cmd_func:
        cmd_func(args)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
